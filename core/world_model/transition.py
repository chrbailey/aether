"""Transition model: f(z_t, a_t, c_t) -> z_hat_{t+1}.

The core prediction engine of the JEPA-style world model. Predicts
the next latent state given the current state, a governance action,
and a process path variant. Operates entirely in latent space,
never reconstructing raw events.

Architecture: MLP with residual connections for stable gradient flow.
"""

from __future__ import annotations

import torch
import torch.nn as nn

from .latent import NUM_VARIANTS


# Governance actions matching TypeScript GovernanceMode.name
GOVERNANCE_ACTIONS: list[str] = ["flexible", "standard", "strict", "forbidden"]
NUM_ACTIONS: int = len(GOVERNANCE_ACTIONS)
ACTION_TO_INDEX: dict[str, int] = {a: i for i, a in enumerate(GOVERNANCE_ACTIONS)}


class ResidualBlock(nn.Module):
    """MLP block with pre-norm residual connection.

    Args:
        dim: Input and output dimension.
        hidden_dim: Hidden layer dimension.
        dropout: Dropout rate.
    """

    def __init__(self, dim: int, hidden_dim: int, dropout: float = 0.1) -> None:
        super().__init__()
        self.norm = nn.LayerNorm(dim)
        self.mlp = nn.Sequential(
            nn.Linear(dim, hidden_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, dim),
            nn.Dropout(dropout),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return x + self.mlp(self.norm(x))


class TransitionModel(nn.Module):
    """Predicts next latent state from current state + action + path variant.

    f(z_t, a_t, c_t) -> z_hat_{t+1}

    The model takes:
        - z_t: Current 128-dim latent state from the encoder
        - a_t: Governance action (one-hot over 4 modes)
        - c_t: Path variant (soft categorical over 6 variants)

    And produces z_hat_{t+1}, the predicted next latent state.

    Multiple futures can be generated by sampling different c_t values,
    enabling the world model to represent multi-modal process outcomes.

    Args:
        latent_dim: Dimension of latent states z_t (default: 128).
        n_actions: Number of governance actions.
        n_variants: Number of path variant categories.
        hidden_dim: Hidden layer dimension in residual blocks.
        n_blocks: Number of residual blocks.
        dropout: Dropout rate.
    """

    def __init__(
        self,
        latent_dim: int = 128,
        n_actions: int = NUM_ACTIONS,
        n_variants: int = NUM_VARIANTS,
        hidden_dim: int = 256,
        n_blocks: int = 3,
        dropout: float = 0.1,
    ) -> None:
        super().__init__()
        self.latent_dim = latent_dim

        # Project action and variant to latent_dim for fusion
        input_dim = latent_dim + n_actions + n_variants
        self.input_proj = nn.Sequential(
            nn.Linear(input_dim, latent_dim),
            nn.LayerNorm(latent_dim),
            nn.GELU(),
        )

        # Residual MLP for state transition
        self.blocks = nn.ModuleList([
            ResidualBlock(latent_dim, hidden_dim, dropout)
            for _ in range(n_blocks)
        ])

        self.output_norm = nn.LayerNorm(latent_dim)

    def forward(
        self,
        z_t: torch.Tensor,
        action: torch.Tensor,
        variant: torch.Tensor,
    ) -> torch.Tensor:
        """Predict next latent state.

        Args:
            z_t: Current latent state (batch, latent_dim).
            action: Governance action, one-hot (batch, n_actions).
            variant: Path variant, soft categorical (batch, n_variants).

        Returns:
            Predicted next latent state z_hat_{t+1} (batch, latent_dim).
        """
        # Concatenate all conditioning inputs
        combined = torch.cat([z_t, action, variant], dim=-1)

        # Project to latent dimension
        h = self.input_proj(combined)

        # Residual blocks with skip from z_t
        for block in self.blocks:
            h = block(h)

        # Final residual from input latent (strong skip for stability)
        return self.output_norm(h + z_t)

    def predict_multiple_futures(
        self,
        z_t: torch.Tensor,
        action: torch.Tensor,
        variant_samples: torch.Tensor,
    ) -> torch.Tensor:
        """Predict multiple futures by sampling different path variants.

        Args:
            z_t: Current latent state (batch, latent_dim).
            action: Governance action (batch, n_actions).
            variant_samples: Multiple variant samples (batch, n_samples, n_variants).

        Returns:
            Predicted future states (batch, n_samples, latent_dim).
        """
        batch_size, n_samples, n_variants = variant_samples.shape

        # Expand z_t and action to match samples
        z_expanded = z_t.unsqueeze(1).expand(-1, n_samples, -1)
        action_expanded = action.unsqueeze(1).expand(-1, n_samples, -1)

        # Flatten for batch processing
        z_flat = z_expanded.reshape(-1, z_t.shape[-1])
        action_flat = action_expanded.reshape(-1, action.shape[-1])
        variant_flat = variant_samples.reshape(-1, n_variants)

        # Predict and reshape
        predictions = self.forward(z_flat, action_flat, variant_flat)
        return predictions.reshape(batch_size, n_samples, -1)
